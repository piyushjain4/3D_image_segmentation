{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation_models_pytorch\n!pip install warmup_scheduler","metadata":{"papermill":{"duration":25.498202,"end_time":"2023-05-05T11:18:15.291251","exception":false,"start_time":"2023-05-05T11:17:49.793049","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:00:54.270929Z","iopub.execute_input":"2023-06-10T12:00:54.271600Z","iopub.status.idle":"2023-06-10T12:01:24.792709Z","shell.execute_reply.started":"2023-06-10T12:00:54.271555Z","shell.execute_reply":"2023-06-10T12:01:24.791435Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting segmentation_models_pytorch\n  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.15.1+cpu)\nCollecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: timm==0.9.2 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.9.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (4.64.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (9.5.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.0.0+cpu)\nRequirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (3.0.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (5.4.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (0.14.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (0.3.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.28.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2023.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (21.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2023.5.7)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=fcfedcf90c6e5d2c62c8ad9367f6f28858eefd0bd6b6f22adbe4e8f2d45ce347\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60966 sha256=8ba6f2834496b5427314254ea616470f87e4dd31e11c8a4e82d54648501d2eb9\n  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: efficientnet-pytorch, pretrainedmodels, segmentation_models_pytorch\nSuccessfully installed efficientnet-pytorch-0.7.1 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting warmup_scheduler\n  Downloading warmup_scheduler-0.3.tar.gz (2.1 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: warmup_scheduler\n  Building wheel for warmup_scheduler (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for warmup_scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2982 sha256=4370a1cd632a79f2fc153d96bb29e20ec46835afc9f4b4c23a07f5c361250c81\n  Stored in directory: /root/.cache/pip/wheels/59/01/9e/d1820991c32916e9808c940f572b462f3e46427f3e76c4d852\nSuccessfully built warmup_scheduler\nInstalling collected packages: warmup_scheduler\nSuccessfully installed warmup_scheduler-0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Imports","metadata":{"papermill":{"duration":0.013144,"end_time":"2023-05-05T11:18:15.318467","exception":false,"start_time":"2023-05-05T11:18:15.305323","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy as sp\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss\nimport matplotlib.pyplot as plt\nimport sys\nimport os\nimport gc\nimport sys\nimport pickle\nimport warnings\nimport math\nimport time\nimport random\nimport argparse\nimport importlib\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nimport segmentation_models_pytorch as smp\nfrom warmup_scheduler import GradualWarmupScheduler\nimport cv2\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nimport datetime","metadata":{"papermill":{"duration":6.666828,"end_time":"2023-05-05T11:18:21.998534","exception":false,"start_time":"2023-05-05T11:18:15.331706","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:24.795250Z","iopub.execute_input":"2023-06-10T12:01:24.795631Z","iopub.status.idle":"2023-06-10T12:01:32.843520Z","shell.execute_reply.started":"2023-06-10T12:01:24.795599Z","shell.execute_reply":"2023-06-10T12:01:32.842503Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import ssl\nssl._create_default_https_context = ssl._create_unverified_context","metadata":{"papermill":{"duration":0.01787,"end_time":"2023-05-05T11:18:22.025589","exception":false,"start_time":"2023-05-05T11:18:22.007719","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:32.844825Z","iopub.execute_input":"2023-06-10T12:01:32.845136Z","iopub.status.idle":"2023-06-10T12:01:32.851915Z","shell.execute_reply.started":"2023-06-10T12:01:32.845110Z","shell.execute_reply":"2023-06-10T12:01:32.850549Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# sys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\n# sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch-master')\n# sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n# sys.path.append('/kaggle/input/segmentation-models-pytorch/segmentation_models.pytorch-master')","metadata":{"papermill":{"duration":0.016181,"end_time":"2023-05-05T11:18:22.051331","exception":false,"start_time":"2023-05-05T11:18:22.03515","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:32.855906Z","iopub.execute_input":"2023-06-10T12:01:32.856242Z","iopub.status.idle":"2023-06-10T12:01:32.868248Z","shell.execute_reply.started":"2023-06-10T12:01:32.856214Z","shell.execute_reply":"2023-06-10T12:01:32.867406Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Main Configuration Class","metadata":{"papermill":{"duration":0.008734,"end_time":"2023-05-05T11:18:22.069062","exception":false,"start_time":"2023-05-05T11:18:22.060328","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class CFG:\n    # ============== comp exp name =============\n    comp_name = 'vesuvius'\n    exp_name = 'tu-regnety_064'\n    comp_dir_path = '/kaggle/input/'\n    comp_folder_name = 'vesuvius-challenge-ink-detection'\n    comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n\n    # ============== pred target =============\n    target_size = 1\n\n    # ============== model cfg =============\n    model_name = 'Unet'\n    backbone = 'tu-regnety_064' #'se_resnext50_32x4d'\n\n    in_chans = 3 # 65\n    # ============== training cfg =============\n    size = 224\n    tile_size = 224\n    stride = tile_size // 4\n\n    train_batch_size = 32 # 32\n    valid_batch_size = train_batch_size * 1\n    use_amp = True\n\n    scheduler = 'GradualWarmupSchedulerV2' # 'GradualWarmupSchedulerV2' # 'CosineAnnealingLR'\n    epochs = 9 # 30\n\n    # adamW warmupあり\n    warmup_factor = 10\n    # lr = 1e-4 / warmup_factor\n    lr = 1e-4 / warmup_factor\n\n    # ============== fold =============\n    valid_id = [1, 2, 3]\n\n    # objective_cv = 'binary'  # 'binary', 'multiclass', 'regression'\n    metric_direction = 'maximize'  # maximize, 'minimize'\n    # metrics = 'dice_coef'\n\n    # ============== fixed =============\n    pretrained = True\n    inf_weight = 'best'  # 'best'\n\n    min_lr = 1e-6\n    weight_decay = 1e-6\n    max_grad_norm = 1000\n\n    print_freq = 50\n    num_workers = 2\n\n    seed = 310\n\n    # ============== set dataset path =============\n    print('set dataset path')\n\n    outputs_path = f'/kaggle/working/outputs/{comp_name}/{exp_name}/'\n\n    submission_dir = outputs_path + 'submissions/'\n    submission_path = submission_dir + f'submission_{exp_name}.csv'\n\n    model_dir = outputs_path + \\\n        f'{comp_name}-models/'\n\n    figures_dir = outputs_path + 'figures/'\n\n    log_dir = outputs_path + 'logs/'\n    log_path = log_dir + f'{exp_name}.txt'\n\n    # ============== augmentation =============\n    train_aug_list = [\n        A.Resize(size, size),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.RandomBrightnessContrast(p=0.75),\n        A.ShiftScaleRotate(p=0.75),\n        A.OneOf([\n                A.GaussNoise(var_limit=[10, 50]),\n                A.GaussianBlur(),\n                A.MotionBlur(),\n                ], p=0.4),\n        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n        A.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3), \n                        mask_fill_value=0, p=0.5),\n        A.Normalize(\n            mean= [0] * in_chans,\n            std= [1] * in_chans\n        ),\n        ToTensorV2(transpose_mask=True),\n    ]\n\n    valid_aug_list = [\n        A.Resize(size, size),\n        A.Normalize(\n            mean= [0] * in_chans,\n            std= [1] * in_chans\n        ),\n        ToTensorV2(transpose_mask=True),\n    ]\n","metadata":{"papermill":{"duration":0.026776,"end_time":"2023-05-05T11:18:22.104551","exception":false,"start_time":"2023-05-05T11:18:22.077775","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:32.869557Z","iopub.execute_input":"2023-06-10T12:01:32.870335Z","iopub.status.idle":"2023-06-10T12:01:32.884386Z","shell.execute_reply.started":"2023-06-10T12:01:32.870290Z","shell.execute_reply":"2023-06-10T12:01:32.883382Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"set dataset path\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Helper Functions (as usual)","metadata":{"papermill":{"duration":0.008569,"end_time":"2023-05-05T11:18:22.121837","exception":false,"start_time":"2023-05-05T11:18:22.113268","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"papermill":{"duration":0.017673,"end_time":"2023-05-05T11:18:22.148255","exception":false,"start_time":"2023-05-05T11:18:22.130582","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:32.885822Z","iopub.execute_input":"2023-06-10T12:01:32.886255Z","iopub.status.idle":"2023-06-10T12:01:32.899709Z","shell.execute_reply.started":"2023-06-10T12:01:32.886217Z","shell.execute_reply":"2023-06-10T12:01:32.898655Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def init_logger(log_file):\n    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\ndef set_seed(seed=None, cudnn_deterministic=True):\n    if seed is None:\n        seed = 310\n    \n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = cudnn_deterministic\n    torch.backends.cudnn.benchmark = False","metadata":{"papermill":{"duration":0.018579,"end_time":"2023-05-05T11:18:22.175538","exception":false,"start_time":"2023-05-05T11:18:22.156959","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:32.901416Z","iopub.execute_input":"2023-06-10T12:01:32.901906Z","iopub.status.idle":"2023-06-10T12:01:32.913505Z","shell.execute_reply.started":"2023-06-10T12:01:32.901869Z","shell.execute_reply":"2023-06-10T12:01:32.912315Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def make_dirs(cfg):\n    for dir in [cfg.model_dir, cfg.figures_dir, cfg.submission_dir, cfg.log_dir]:\n        os.makedirs(dir, exist_ok=True)","metadata":{"papermill":{"duration":0.016631,"end_time":"2023-05-05T11:18:22.201234","exception":false,"start_time":"2023-05-05T11:18:22.184603","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:32.914677Z","iopub.execute_input":"2023-06-10T12:01:32.914996Z","iopub.status.idle":"2023-06-10T12:01:32.927485Z","shell.execute_reply.started":"2023-06-10T12:01:32.914954Z","shell.execute_reply":"2023-06-10T12:01:32.926478Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def cfg_init(cfg, mode='train'):\n    set_seed(cfg.seed)\n\n    if mode == 'train':\n        make_dirs(cfg)","metadata":{"papermill":{"duration":0.018242,"end_time":"2023-05-05T11:18:22.228243","exception":false,"start_time":"2023-05-05T11:18:22.210001","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:32.928915Z","iopub.execute_input":"2023-06-10T12:01:32.929252Z","iopub.status.idle":"2023-06-10T12:01:32.949778Z","shell.execute_reply.started":"2023-06-10T12:01:32.929220Z","shell.execute_reply":"2023-06-10T12:01:32.948454Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"cfg_init(CFG)\n\nLogger = init_logger(log_file=CFG.log_path)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"papermill":{"duration":0.074764,"end_time":"2023-05-05T11:18:22.311844","exception":false,"start_time":"2023-05-05T11:18:22.23708","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:32.950923Z","iopub.execute_input":"2023-06-10T12:01:32.951344Z","iopub.status.idle":"2023-06-10T12:01:32.969301Z","shell.execute_reply.started":"2023-06-10T12:01:32.951305Z","shell.execute_reply":"2023-06-10T12:01:32.968335Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Image and Mask (by mask, it means the inklabels.png)\n\n### The mask will act as the label for segmentation.","metadata":{"papermill":{"duration":0.008969,"end_time":"2023-05-05T11:18:22.329936","exception":false,"start_time":"2023-05-05T11:18:22.320967","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def read_image_mask(fragment_id):\n\n    images = []\n    \n    mid = 65 // 2\n    start = 29\n    end = 32\n    idxs = range(start, end)\n\n    for i in tqdm(idxs):\n        \n        image = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n\n        pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n        pad1 = (CFG.tile_size - image.shape[1] % CFG.tile_size)\n\n        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n\n        images.append(image)\n    images = np.stack(images, axis=2)\n\n    mask = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/inklabels.png\", 0)\n    mask = np.pad(mask, [(0, pad0), (0, pad1)], constant_values=0)\n\n    mask = mask.astype('float32')\n    mask /= 255.0\n    \n    return images, mask","metadata":{"papermill":{"duration":0.021078,"end_time":"2023-05-05T11:18:22.359884","exception":false,"start_time":"2023-05-05T11:18:22.338806","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:32.973762Z","iopub.execute_input":"2023-06-10T12:01:32.974115Z","iopub.status.idle":"2023-06-10T12:01:32.982954Z","shell.execute_reply.started":"2023-06-10T12:01:32.974087Z","shell.execute_reply":"2023-06-10T12:01:32.981600Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_train_valid_dataset(valid_id):\n    train_images = []\n    train_masks = []\n\n    valid_images = []\n    valid_masks = []\n    valid_xyxys = []\n\n    for fragment_id in range(1, 4):\n\n        image, mask = read_image_mask(fragment_id)\n\n        x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n        y1_list = list(range(0, image.shape[0]-CFG.tile_size+1, CFG.stride))\n\n        for y1 in y1_list:\n            for x1 in x1_list:\n                y2 = y1 + CFG.tile_size\n                x2 = x1 + CFG.tile_size\n                # xyxys.append((x1, y1, x2, y2))\n        \n                if fragment_id == valid_id:\n                    valid_images.append(image[y1:y2, x1:x2])\n                    valid_masks.append(mask[y1:y2, x1:x2, None])\n\n                    valid_xyxys.append([x1, y1, x2, y2])\n                else:\n                    train_images.append(image[y1:y2, x1:x2])\n                    train_masks.append(mask[y1:y2, x1:x2, None])\n\n    return train_images, train_masks, valid_images, valid_masks, valid_xyxys","metadata":{"papermill":{"duration":0.021229,"end_time":"2023-05-05T11:18:22.390301","exception":false,"start_time":"2023-05-05T11:18:22.369072","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:32.984768Z","iopub.execute_input":"2023-06-10T12:01:32.985102Z","iopub.status.idle":"2023-06-10T12:01:32.995384Z","shell.execute_reply.started":"2023-06-10T12:01:32.985073Z","shell.execute_reply":"2023-06-10T12:01:32.994524Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Classes","metadata":{"papermill":{"duration":0.008841,"end_time":"2023-05-05T11:18:22.407843","exception":false,"start_time":"2023-05-05T11:18:22.399002","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_transforms(data, cfg):\n    if data == 'train':\n        aug = A.Compose(cfg.train_aug_list)\n    elif data == 'valid':\n        aug = A.Compose(cfg.valid_aug_list)\n    return aug\n\nclass CustomDataset(Dataset):\n    def __init__(self, images, cfg, labels=None, transform=None):\n        self.images = images\n        self.cfg = cfg\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n\n        if self.transform:\n            data = self.transform(image=image, mask=label)\n            image = data['image']\n            label = data['mask']\n\n        return image, label","metadata":{"papermill":{"duration":0.02047,"end_time":"2023-05-05T11:18:22.437131","exception":false,"start_time":"2023-05-05T11:18:22.416661","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:32.996559Z","iopub.execute_input":"2023-06-10T12:01:32.996969Z","iopub.status.idle":"2023-06-10T12:01:33.014741Z","shell.execute_reply.started":"2023-06-10T12:01:32.996932Z","shell.execute_reply":"2023-06-10T12:01:33.013568Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Visualization of the Data","metadata":{"papermill":{"duration":0.008855,"end_time":"2023-05-05T11:18:22.454738","exception":false,"start_time":"2023-05-05T11:18:22.445883","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# train_images, train_masks, valid_images, valid_masks, valid_xyxys = get_train_valid_dataset(1)\n# valid_xyxys = np.stack(valid_xyxys)","metadata":{"papermill":{"duration":0.016635,"end_time":"2023-05-05T11:18:22.480428","exception":false,"start_time":"2023-05-05T11:18:22.463793","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:33.016243Z","iopub.execute_input":"2023-06-10T12:01:33.016598Z","iopub.status.idle":"2023-06-10T12:01:33.029408Z","shell.execute_reply.started":"2023-06-10T12:01:33.016569Z","shell.execute_reply":"2023-06-10T12:01:33.028125Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# plot_dataset = CustomDataset(\n#     train_images, CFG, labels=train_masks)\n\n# transform = CFG.train_aug_list\n# transform = A.Compose(\n#     [t for t in transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n\n\n# plot_count = 0\n# for i in range(1000):\n\n#     image, mask = plot_dataset[i]\n#     data = transform(image=image, mask=mask)\n#     aug_image = data['image']\n#     aug_mask = data['mask']\n\n#     if mask.sum() == 0:\n#         continue\n\n#     fig, axes = plt.subplots(1, 4, figsize=(15, 8))\n#     axes[0].imshow(image[..., 0], cmap=\"gray\")\n#     axes[1].imshow(mask, cmap=\"gray\")\n#     axes[2].imshow(aug_image[..., 0], cmap=\"gray\")\n#     axes[3].imshow(aug_mask, cmap=\"gray\")\n    \n#     plt.savefig(CFG.figures_dir + f'aug_fold_{CFG.valid_id}_{plot_count}.png')\n\n#     plot_count += 1\n#     if plot_count == 5:\n#         break","metadata":{"papermill":{"duration":0.016925,"end_time":"2023-05-05T11:18:22.50599","exception":false,"start_time":"2023-05-05T11:18:22.489065","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:33.030985Z","iopub.execute_input":"2023-06-10T12:01:33.031428Z","iopub.status.idle":"2023-06-10T12:01:33.042783Z","shell.execute_reply.started":"2023-06-10T12:01:33.031398Z","shell.execute_reply":"2023-06-10T12:01:33.041523Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Some memory cleaning (coz there's not infinite RAM)","metadata":{"papermill":{"duration":0.008629,"end_time":"2023-05-05T11:18:22.523314","exception":false,"start_time":"2023-05-05T11:18:22.514685","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# del plot_dataset\n# del train_images\n# del train_masks\n# del valid_images\n# del valid_masks\n# del valid_xyxys\n# gc.collect()","metadata":{"papermill":{"duration":0.016503,"end_time":"2023-05-05T11:18:22.548704","exception":false,"start_time":"2023-05-05T11:18:22.532201","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:33.044431Z","iopub.execute_input":"2023-06-10T12:01:33.044913Z","iopub.status.idle":"2023-06-10T12:01:33.063784Z","shell.execute_reply.started":"2023-06-10T12:01:33.044822Z","shell.execute_reply":"2023-06-10T12:01:33.062708Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Model (finally the good stuff)","metadata":{"papermill":{"duration":0.008703,"end_time":"2023-05-05T11:18:22.566039","exception":false,"start_time":"2023-05-05T11:18:22.557336","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, cfg, weight=None):\n        super().__init__()\n        self.cfg = cfg\n\n        self.encoder = smp.Unet(\n            encoder_name=cfg.backbone, \n            encoder_weights=weight,\n            in_channels=cfg.in_chans,\n            classes=cfg.target_size,\n            activation=None,\n        )\n\n    def forward(self, image):\n        output = self.encoder(image)\n        # output = output.squeeze(-1)\n        return output","metadata":{"papermill":{"duration":0.017369,"end_time":"2023-05-05T11:18:22.592119","exception":false,"start_time":"2023-05-05T11:18:22.57475","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:33.065306Z","iopub.execute_input":"2023-06-10T12:01:33.065648Z","iopub.status.idle":"2023-06-10T12:01:33.077592Z","shell.execute_reply.started":"2023-06-10T12:01:33.065617Z","shell.execute_reply":"2023-06-10T12:01:33.076277Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def build_model(cfg, weight=\"imagenet\"):\n    print('model_name', cfg.model_name)\n    print('backbone', cfg.backbone)\n\n    model = CustomModel(cfg, weight)\n\n    return model","metadata":{"papermill":{"duration":0.016285,"end_time":"2023-05-05T11:18:22.617389","exception":false,"start_time":"2023-05-05T11:18:22.601104","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:33.079072Z","iopub.execute_input":"2023-06-10T12:01:33.079712Z","iopub.status.idle":"2023-06-10T12:01:33.091433Z","shell.execute_reply.started":"2023-06-10T12:01:33.079669Z","shell.execute_reply":"2023-06-10T12:01:33.090261Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Scheduler","metadata":{"papermill":{"duration":0.008599,"end_time":"2023-05-05T11:18:22.634802","exception":false,"start_time":"2023-05-05T11:18:22.626203","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    \"\"\"\n    https://www.kaggle.com/code/underwearfitting/single-fold-training-of-resnet200d-lb0-965\n    \"\"\"\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(\n            optimizer, multiplier, total_epoch, after_scheduler)\n\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [\n                        base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n\ndef get_scheduler(cfg, optimizer):\n    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, cfg.epochs, eta_min=1e-7)\n    scheduler = GradualWarmupSchedulerV2(\n        optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n\n    return scheduler\n\ndef scheduler_step(scheduler, avg_val_loss, epoch):\n    scheduler.step()\n","metadata":{"papermill":{"duration":0.020825,"end_time":"2023-05-05T11:18:22.664749","exception":false,"start_time":"2023-05-05T11:18:22.643924","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:33.092834Z","iopub.execute_input":"2023-06-10T12:01:33.093258Z","iopub.status.idle":"2023-06-10T12:01:33.105419Z","shell.execute_reply.started":"2023-06-10T12:01:33.093221Z","shell.execute_reply":"2023-06-10T12:01:33.104380Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Initializing the Model, optimizer and the scheduler","metadata":{"papermill":{"duration":0.008637,"end_time":"2023-05-05T11:18:22.6821","exception":false,"start_time":"2023-05-05T11:18:22.673463","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# model = build_model(CFG)\n# model.to(device)\n\n# optimizer = AdamW(model.parameters(), lr=CFG.lr)\n# scheduler = get_scheduler(CFG, optimizer)","metadata":{"papermill":{"duration":0.015421,"end_time":"2023-05-05T11:18:22.706247","exception":false,"start_time":"2023-05-05T11:18:22.690826","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:33.106900Z","iopub.execute_input":"2023-06-10T12:01:33.107329Z","iopub.status.idle":"2023-06-10T12:01:33.122003Z","shell.execute_reply.started":"2023-06-10T12:01:33.107290Z","shell.execute_reply":"2023-06-10T12:01:33.120903Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Losses","metadata":{"papermill":{"duration":0.008587,"end_time":"2023-05-05T11:18:22.723548","exception":false,"start_time":"2023-05-05T11:18:22.714961","status":"completed"},"tags":[]}},{"cell_type":"code","source":"alpha = 0.5\nbeta = 1 - alpha\n\nDiceLoss = smp.losses.DiceLoss(mode='binary')\nBCELoss = smp.losses.SoftBCEWithLogitsLoss()\nTverskyLoss = smp.losses.TverskyLoss(mode='binary', log_loss=False, alpha=alpha, beta=beta)","metadata":{"papermill":{"duration":0.01692,"end_time":"2023-05-05T11:18:22.74915","exception":false,"start_time":"2023-05-05T11:18:22.73223","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:33.123850Z","iopub.execute_input":"2023-06-10T12:01:33.124448Z","iopub.status.idle":"2023-06-10T12:01:33.135819Z","shell.execute_reply.started":"2023-06-10T12:01:33.124414Z","shell.execute_reply":"2023-06-10T12:01:33.134874Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def criterion(y_pred, y_true):\n    return 0.5 * BCELoss(y_pred, y_true) + 0.5 * DiceLoss(y_pred, y_true)\n#     return DiceLoss(y_pred, y_true)\n    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * TverskyLoss(y_pred, y_true)\n#     return BCELoss(y_pred, y_true)","metadata":{"papermill":{"duration":0.017211,"end_time":"2023-05-05T11:18:22.775107","exception":false,"start_time":"2023-05-05T11:18:22.757896","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:33.137260Z","iopub.execute_input":"2023-06-10T12:01:33.138288Z","iopub.status.idle":"2023-06-10T12:01:33.149355Z","shell.execute_reply.started":"2023-06-10T12:01:33.138256Z","shell.execute_reply":"2023-06-10T12:01:33.148395Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Training and Validation Function","metadata":{"papermill":{"duration":0.009209,"end_time":"2023-05-05T11:18:22.793142","exception":false,"start_time":"2023-05-05T11:18:22.783933","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer, device):\n    model.train()\n\n    scaler = GradScaler(enabled=CFG.use_amp)\n    losses = AverageMeter()\n\n    for step, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        with autocast(CFG.use_amp):\n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n\n        losses.update(loss.item(), batch_size)\n        scaler.scale(loss).backward()\n\n        grad_norm = torch.nn.utils.clip_grad_norm_(\n            model.parameters(), CFG.max_grad_norm)\n\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n\n    return losses.avg\n\ndef valid_fn(valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt):\n    mask_pred = np.zeros(valid_mask_gt.shape)\n    mask_count = np.zeros(valid_mask_gt.shape)\n\n    model.eval()\n    losses = AverageMeter()\n\n    for step, (images, labels) in tqdm(enumerate(valid_loader), total=len(valid_loader)):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        with torch.no_grad():\n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n\n        # make whole mask\n        y_preds = torch.sigmoid(y_preds).to('cpu').numpy()\n        start_idx = step*CFG.valid_batch_size\n        end_idx = start_idx + batch_size\n        for i, (x1, y1, x2, y2) in enumerate(valid_xyxys[start_idx:end_idx]):\n            mask_pred[y1:y2, x1:x2] += y_preds[i].squeeze(0)\n            mask_count[y1:y2, x1:x2] += np.ones((CFG.tile_size, CFG.tile_size))\n\n    print(f'mask_count_min: {mask_count.min()}')\n    mask_pred /= mask_count\n    return losses.avg, mask_pred","metadata":{"papermill":{"duration":0.023731,"end_time":"2023-05-05T11:18:22.825566","exception":false,"start_time":"2023-05-05T11:18:22.801835","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:33.150560Z","iopub.execute_input":"2023-06-10T12:01:33.151036Z","iopub.status.idle":"2023-06-10T12:01:33.168102Z","shell.execute_reply.started":"2023-06-10T12:01:33.151008Z","shell.execute_reply":"2023-06-10T12:01:33.167213Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Metrics for the competition","metadata":{"papermill":{"duration":0.00856,"end_time":"2023-05-05T11:18:22.842736","exception":false,"start_time":"2023-05-05T11:18:22.834176","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.metrics import fbeta_score\n\ndef fbeta_numpy(targets, preds, beta=0.5, smooth=1e-5):\n    \"\"\"\n    https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n    \"\"\"\n    y_true_count = targets.sum()\n    ctp = preds[targets==1].sum()\n    cfp = preds[targets==0].sum()\n    beta_squared = beta * beta\n\n    c_precision = ctp / (ctp + cfp + smooth)\n    c_recall = ctp / (y_true_count + smooth)\n    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n\n    return dice\n\ndef calc_fbeta(mask, mask_pred):\n    mask = mask.astype(int).flatten()\n    mask_pred = mask_pred.flatten()\n\n    best_th = 0\n    best_dice = 0\n    for th in np.array(range(10, 50+1, 5)) / 100:\n        \n        # dice = fbeta_score(mask, (mask_pred >= th).astype(int), beta=0.5)\n        dice = fbeta_numpy(mask, (mask_pred >= th).astype(int), beta=0.5)\n        print(f'th: {th}, fbeta: {dice}')\n\n        if dice > best_dice:\n            best_dice = dice\n            best_th = th\n    \n    Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\n    return best_dice, best_th\n\n\ndef calc_cv(mask_gt, mask_pred):\n    best_dice, best_th = calc_fbeta(mask_gt, mask_pred)\n\n    return best_dice, best_th","metadata":{"papermill":{"duration":0.021131,"end_time":"2023-05-05T11:18:22.872531","exception":false,"start_time":"2023-05-05T11:18:22.8514","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:33.169266Z","iopub.execute_input":"2023-06-10T12:01:33.169745Z","iopub.status.idle":"2023-06-10T12:01:33.185888Z","shell.execute_reply.started":"2023-06-10T12:01:33.169717Z","shell.execute_reply":"2023-06-10T12:01:33.184823Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Main","metadata":{"papermill":{"duration":0.008606,"end_time":"2023-05-05T11:18:22.889759","exception":false,"start_time":"2023-05-05T11:18:22.881153","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for fold in CFG.valid_id:\n    \n    train_images, train_masks, valid_images, valid_masks, valid_xyxys = get_train_valid_dataset(fold)\n    valid_xyxys = np.stack(valid_xyxys)\n    \n    \n    train_dataset = CustomDataset(train_images, CFG, labels=train_masks,\n                                  transform=get_transforms(data='train', cfg=CFG))\n\n    valid_dataset = CustomDataset(valid_images, CFG, labels=valid_masks,\n                                  transform=get_transforms(data='valid', cfg=CFG))\n\n    train_loader = DataLoader(train_dataset,\n                              batch_size=CFG.train_batch_size,\n                              shuffle=True,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n                              )\n\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=CFG.valid_batch_size,\n                              shuffle=False,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    \n    valid_mask_gt = cv2.imread(CFG.comp_dataset_path + f\"train/{fold}/inklabels.png\", 0)\n    valid_mask_gt = valid_mask_gt / 255\n    pad0 = (CFG.tile_size - valid_mask_gt.shape[0] % CFG.tile_size)\n    pad1 = (CFG.tile_size - valid_mask_gt.shape[1] % CFG.tile_size)\n    valid_mask_gt = np.pad(valid_mask_gt, [(0, pad0), (0, pad1)], constant_values=0)\n    \n    \n    if CFG.metric_direction == 'minimize':\n        best_score = np.inf\n    elif CFG.metric_direction == 'maximize':\n        best_score = -1\n\n    best_loss = np.inf\n    \n    model = build_model(CFG)\n    model.to(device)\n\n    optimizer = AdamW(model.parameters(), lr=CFG.lr)\n    scheduler = get_scheduler(CFG, optimizer)\n\n    for epoch in range(CFG.epochs):\n\n        start_time = time.time()\n\n        # train\n        avg_loss = train_fn(train_loader, model, criterion, optimizer, device)\n\n        # eval\n        avg_val_loss, mask_pred = valid_fn(\n            valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt)\n\n        scheduler_step(scheduler, avg_val_loss, epoch)\n#         scheduler.step()\n\n        best_dice, best_th = calc_cv(valid_mask_gt, mask_pred)\n\n        # score = avg_val_loss\n        score = best_dice\n\n        elapsed = time.time() - start_time\n\n        Logger.info(\n            f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        # Logger.info(f'Epoch {epoch+1} - avgScore: {avg_score:.4f}')\n        Logger.info(\n            f'Epoch {epoch+1} - avgScore: {score:.4f}')\n\n        if CFG.metric_direction == 'minimize':\n            update_best = score < best_score\n        elif CFG.metric_direction == 'maximize':\n            update_best = score > best_score\n\n        if update_best:\n            best_loss = avg_val_loss\n            best_score = score\n\n            Logger.info(\n                f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            Logger.info(\n                f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n\n            torch.save({'model': model.state_dict()},\n                        CFG.model_dir + f'{CFG.model_name}_fold{fold}_best.pth')\n        torch.cuda.empty_cache()\n        gc.collect()\n    del model\n    gc.collect()\n    del optimizer\n    del scheduler\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"papermill":{"duration":9764.304164,"end_time":"2023-05-05T14:01:07.202601","exception":false,"start_time":"2023-05-05T11:18:22.898437","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-10T12:01:33.187190Z","iopub.execute_input":"2023-06-10T12:01:33.187530Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e1e4a01b22943f3903d2945c8a43967"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c2c4858fadf434c81f105a2f891f91e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc724f9146ce42f8833b5131af218180"}},"metadata":{}},{"name":"stdout","text":"model_name Unet\nbackbone tu-regnety_064\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/123M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fc20b24d81443c8839bfd9930c51077"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1786 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55532b04d5a04e81929d79fd0cdf0098"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.051419,"end_time":"2023-05-05T14:01:07.30637","exception":false,"start_time":"2023-05-05T14:01:07.254951","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}